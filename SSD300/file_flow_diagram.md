# SSD300 File Interaction Flow

## Overview
This diagram shows how the Jupyter notebook interacts with the Python scripts in the `src/` folder during training and evaluation.

## File Structure
```
SSD300/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ssd300_enhanced_pipeline.ipynb    # Main interface
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ coco_voc.py                       # Dataset loader
â”‚   â”œâ”€â”€ train_ssd.py                      # Training script
â”‚   â”œâ”€â”€ eval_ssd.py                       # Evaluation script
â”‚   â”œâ”€â”€ voc2coco.py                       # Data converter
â”‚   â”œâ”€â”€ voc_dataset.py                    # VOC dataset loader
â”‚   â””â”€â”€ visualize_dataset.py              # Visualization tools
â””â”€â”€ outputs/                              # Generated files
```

## File Interaction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ““ ssd300_enhanced_pipeline.ipynb                     â”‚
â”‚                    (Main Control Center)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚             â”‚             â”‚
                    â–¼             â–¼             â–¼
          
    ğŸ“ DATA PREPARATION     ğŸ§  MODEL TRAINING    ğŸ” EVALUATION
                            
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    NOTEBOOK CELL    â”‚   â”‚    NOTEBOOK CELL    â”‚   â”‚    NOTEBOOK CELL    â”‚
â”‚                     â”‚   â”‚                     â”‚   â”‚                     â”‚
â”‚ # Convert VOCâ†’COCO  â”‚   â”‚ # Train SSD300      â”‚   â”‚ # Evaluate Model    â”‚
â”‚ os.system(          â”‚   â”‚ from SSD300.src     â”‚   â”‚ from SSD300.src     â”‚
â”‚   "python src/      â”‚   â”‚ import coco_voc     â”‚   â”‚ import coco_voc     â”‚
â”‚    voc2coco.py"     â”‚   â”‚                     â”‚   â”‚                     â”‚
â”‚ )                   â”‚   â”‚ dataset =           â”‚   â”‚ dataset =           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ COCODetectionDatasetâ”‚   â”‚ COCODetectionDatasetâ”‚
          â”‚               â”‚ model = ssd300_vgg16â”‚   â”‚ model.load_state_   â”‚
          â–¼               â”‚                     â”‚   â”‚ dict(torch.load())  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ # Training loop     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  ğŸ“„ voc2coco.py     â”‚   â”‚ for epoch in range: â”‚             â”‚
â”‚                     â”‚   â”‚   for batch:        â”‚             â–¼
â”‚ def convert_xmls_   â”‚   â”‚     loss = model()  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ to_cocojson()       â”‚   â”‚     loss.backward() â”‚   â”‚  ğŸ“„ eval_ssd.py     â”‚
â”‚                     â”‚   â”‚     optimizer.step()â”‚   â”‚                     â”‚
â”‚ # Reads XML files   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ def evaluate_model()â”‚
â”‚ # Converts to COCO  â”‚             â”‚               â”‚                     â”‚
â”‚ # Saves JSON        â”‚             â–¼               â”‚ # Loads model       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ # Runs inference    â”‚
          â”‚               â”‚  ğŸ“„ coco_voc.py     â”‚   â”‚ # Computes metrics  â”‚
          â–¼               â”‚                     â”‚   â”‚ # Saves results     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ class COCODetection â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  ğŸ“Š voc2012_coco.   â”‚   â”‚ Dataset:            â”‚             â”‚
â”‚      json           â”‚   â”‚                     â”‚             â–¼
â”‚                     â”‚   â”‚ def __init__()      â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # COCO format       â”‚   â”‚ def __getitem__()   â”‚   â”‚  ğŸ“Š Results Files   â”‚
â”‚ # annotations       â”‚   â”‚ def __len__()       â”‚   â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                     â”‚   â”‚ predictions.json    â”‚
                          â”‚ # Loads images      â”‚   â”‚ metrics.json        â”‚
                          â”‚ # Loads annotations â”‚   â”‚ training_log.json   â”‚
                          â”‚ # Applies transformsâ”‚   â”‚ visualizations.png  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detailed Flow Steps

### 1. **Data Preparation Flow**
```
Notebook Cell 4 â†’ os.system() â†’ src/voc2coco.py â†’ data/voc2012_coco.json
```

### 2. **Training Flow**
```
Notebook Cell 7 â†’ import src/coco_voc.py â†’ COCODetectionDataset() â†’ Training Loop
```

### 3. **Evaluation Flow**
```
Notebook Cell 9 â†’ import src/coco_voc.py â†’ evaluate_model() â†’ Results JSON
```

## Key Import Statements in Notebook

```python
# In notebook cells:
sys.path.append(os.path.join(os.getcwd(), '..', '..'))
from SSD300.src.coco_voc import COCODetectionDataset  # Dataset loading
```

## File Dependencies

```
ğŸ““ ssd300_enhanced_pipeline.ipynb
    â”‚
    â”œâ”€â”€ ğŸ“„ src/voc2coco.py          (called via os.system)
    â”œâ”€â”€ ğŸ“„ src/coco_voc.py          (imported directly)
    â”œâ”€â”€ ğŸ“„ src/eval_ssd.py          (functions imported)
    â””â”€â”€ ğŸ“„ src/visualize_dataset.py (functions imported)

ğŸ“„ src/coco_voc.py
    â”œâ”€â”€ PIL (Image loading)
    â”œâ”€â”€ torch (Tensor operations)
    â””â”€â”€ pycocotools.coco (COCO format)

ğŸ“„ src/voc2coco.py
    â”œâ”€â”€ xml.etree.ElementTree (XML parsing)
    â””â”€â”€ json (JSON output)
```

## Data Flow Between Files

```
VOC XML Files â†’ voc2coco.py â†’ COCO JSON â†’ coco_voc.py â†’ PyTorch Tensors â†’ Model
                                   â†‘
                              Notebook manages this flow
```

## Output Files Generated

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ssd300_final.pth          # Final trained model
â”‚   â””â”€â”€ ssd300_epoch_*.pth        # Epoch checkpoints
â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ ssd300_predictions.json   # Full evaluation results
â”‚   â””â”€â”€ ssd300_comparison_results.json # Comparison images
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ ssd300_training_*.log     # Training logs
â”‚   â””â”€â”€ training_log.json         # Training metrics
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ training_analysis.png     # Training dashboard
â”‚   â””â”€â”€ comparison_predictions.png # Prediction visualizations
â””â”€â”€ ssd300_final_report.json      # Comprehensive report
```

This flow allows you to control everything from the notebook while leveraging the modular Python scripts for specific tasks.