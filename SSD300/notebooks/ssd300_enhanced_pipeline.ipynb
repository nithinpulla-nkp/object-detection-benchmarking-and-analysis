{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD300 Object Detection - Complete Training & Evaluation Pipeline\n",
    "\n",
    "This notebook provides a comprehensive implementation for training and evaluating SSD300 on Pascal VOC 2012 dataset with enhanced visualizations, logging, and model comparison capabilities.\n",
    "\n",
    "## Features:\n",
    "- Complete training pipeline with real-time logging\n",
    "- Comprehensive evaluation with COCO metrics\n",
    "- Enhanced visualizations and performance analysis\n",
    "- Model comparison support using predefined test images\n",
    "- Detailed logging and progress tracking\n",
    "- Professional reporting and result export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import ssd300_vgg16, SSD300_VGG16_Weights\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead\n",
    "from torchvision.ops import nms\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "from SSD300.src.coco_voc import COCODetectionDataset\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {DEVICE}\")\n",
    "print(f\"üìÖ Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Pascal VOC classes\n",
    "VOC_CLASSES = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "    \"bus\", \"car\", \"cat\", \"chair\", \"cow\",\n",
    "    \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "os.makedirs(\"outputs/logs\", exist_ok=True)\n",
    "os.makedirs(\"outputs/visualizations\", exist_ok=True)\n",
    "os.makedirs(\"outputs/models\", exist_ok=True)\n",
    "os.makedirs(\"outputs/predictions\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enhanced Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup comprehensive logging\n",
    "def setup_logging():\n",
    "    \"\"\"Setup logging configuration for training session.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file = f\"outputs/logs/ssd300_training_{timestamp}.log\"\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"üöÄ SSD300 Training Session Started\")\n",
    "    logger.info(f\"üìù Log file: {log_file}\")\n",
    "    logger.info(f\"üñ•Ô∏è  Device: {DEVICE}\")\n",
    "    \n",
    "    return logger, log_file\n",
    "\n",
    "logger, log_file = setup_logging()\n",
    "print(f\"‚úÖ Logging setup complete: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Comparison Images Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load comparison images configuration\n",
    "COMPARISON_CONFIG_PATH = \"../../comparison_images.json\"\n",
    "\n",
    "try:\n",
    "    with open(COMPARISON_CONFIG_PATH, 'r') as f:\n",
    "        comparison_config = json.load(f)\n",
    "    \n",
    "    comparison_images = comparison_config['images']\n",
    "    logger.info(f\"üì∏ Loaded {len(comparison_images)} comparison images for model evaluation\")\n",
    "    \n",
    "    # Display sample images info\n",
    "    print(\"üîç Sample comparison images:\")\n",
    "    for i, img_info in enumerate(comparison_images[:5]):\n",
    "        print(f\"  {i+1}. {img_info['filename']} - {img_info['description']}\")\n",
    "    print(f\"  ... and {len(comparison_images)-5} more images\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    logger.warning(f\"‚ö†Ô∏è  Comparison config not found at {COMPARISON_CONFIG_PATH}\")\n",
    "    comparison_images = []\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'batch_size': 4,\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_classes': 21,\n",
    "    'image_size': 300,\n",
    "    'confidence_threshold': 0.3,\n",
    "    'nms_threshold': 0.45\n",
    "}\n",
    "\n",
    "logger.info(f\"‚öôÔ∏è  Training configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation with Progress Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (update according to your setup)\n",
    "DATA_CONFIG = {\n",
    "    'voc_data_dir': \"../../data/VOCdevkit/VOC2012\",\n",
    "    'images_dir': \"../../data/VOCdevkit/VOC2012/JPEGImages\",\n",
    "    'annotations_dir': \"../../data/VOCdevkit/VOC2012/Annotations\",\n",
    "    'trainval_ids': \"../../data/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt\",\n",
    "    'coco_json_path': \"../../data/voc2012_coco.json\",\n",
    "    'labels_file': \"../../data/labels.txt\"\n",
    "}\n",
    "\n",
    "# Create labels file\n",
    "logger.info(\"üìù Creating Pascal VOC labels file...\")\n",
    "os.makedirs(os.path.dirname(DATA_CONFIG['labels_file']), exist_ok=True)\n",
    "with open(DATA_CONFIG['labels_file'], 'w') as f:\n",
    "    for cls in VOC_CLASSES:\n",
    "        f.write(f\"{cls}\\n\")\n",
    "\n",
    "# Check if COCO conversion is needed\n",
    "if not os.path.exists(DATA_CONFIG['coco_json_path']):\n",
    "    logger.info(\"üîÑ Converting VOC annotations to COCO format...\")\n",
    "    conversion_cmd = f\"\"\"\n",
    "    python ../src/voc2coco.py \\\n",
    "      --ann_dir {DATA_CONFIG['annotations_dir']} \\\n",
    "      --ann_ids {DATA_CONFIG['trainval_ids']} \\\n",
    "      --labels {DATA_CONFIG['labels_file']} \\\n",
    "      --output {DATA_CONFIG['coco_json_path']} \\\n",
    "      --ext xml \\\n",
    "      --extract_num_from_imgid\n",
    "    \"\"\"\n",
    "    \n",
    "    result = os.system(conversion_cmd.strip())\n",
    "    if result == 0:\n",
    "        logger.info(f\"‚úÖ VOC to COCO conversion completed: {DATA_CONFIG['coco_json_path']}\")\n",
    "    else:\n",
    "        logger.error(f\"‚ùå VOC to COCO conversion failed\")\n",
    "        raise RuntimeError(\"Data preparation failed\")\n",
    "else:\n",
    "    logger.info(f\"‚úÖ COCO annotations already exist: {DATA_CONFIG['coco_json_path']}\")\n",
    "\n",
    "print(f\"üìä Dataset configuration: {DATA_CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhanced Dataset Loading with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    \"\"\"Get transforms for SSD300 input preprocessing.\"\"\"\n",
    "    return T.Compose([\n",
    "        T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.48235, 0.45882, 0.40784], \n",
    "                   std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for object detection.\"\"\"\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Create dataset and analyze\n",
    "logger.info(\"üìä Loading and analyzing dataset...\")\n",
    "dataset = COCODetectionDataset(\n",
    "    DATA_CONFIG['coco_json_path'], \n",
    "    DATA_CONFIG['images_dir'], \n",
    "    transform=get_transform()\n",
    ")\n",
    "\n",
    "# Dataset statistics\n",
    "coco_gt = COCO(DATA_CONFIG['coco_json_path'])\n",
    "dataset_stats = {\n",
    "    'total_images': len(dataset),\n",
    "    'total_annotations': len(coco_gt.anns),\n",
    "    'categories': len(coco_gt.cats),\n",
    "    'avg_annotations_per_image': len(coco_gt.anns) / len(dataset)\n",
    "}\n",
    "\n",
    "logger.info(f\"üìà Dataset Statistics: {dataset_stats}\")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if DEVICE.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset ready: {len(dataset)} images, {len(dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Setup with Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SSD300 model\n",
    "logger.info(\"üß† Initializing SSD300 model...\")\n",
    "model = ssd300_vgg16(weights=SSD300_VGG16_Weights.COCO_V1)\n",
    "\n",
    "# Replace classification head for Pascal VOC\n",
    "model.head.classification_head = SSDClassificationHead(\n",
    "    in_channels=[512, 1024, 512, 256, 256, 256],\n",
    "    num_anchors=[4, 6, 6, 6, 4, 4],\n",
    "    num_classes=CONFIG['num_classes']\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Model analysis\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "model_info = {\n",
    "    'total_parameters': total_params,\n",
    "    'trainable_parameters': trainable_params,\n",
    "    'frozen_parameters': frozen_params,\n",
    "    'model_size_mb': total_params * 4 / (1024 * 1024),  # Assuming float32\n",
    "    'device': str(DEVICE)\n",
    "}\n",
    "\n",
    "logger.info(f\"üîß Model Info: {model_info}\")\n",
    "\n",
    "# Setup optimizer with logging\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "print(f\"‚úÖ Model ready on {DEVICE}\")\n",
    "print(f\"üìä Parameters: {total_params:,} total, {trainable_params:,} trainable\")\n",
    "print(f\"üíæ Estimated model size: {model_info['model_size_mb']:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Enhanced Training Loop with Real-time Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training tracking variables\n",
    "training_log = {\n",
    "    'epoch_losses': [],\n",
    "    'batch_losses': [],\n",
    "    'learning_rates': [],\n",
    "    'training_times': [],\n",
    "    'start_time': time.time()\n",
    "}\n",
    "\n",
    "# Training function with enhanced logging\n",
    "def train_model(model, dataloader, optimizer, num_epochs, device):\n",
    "    \"\"\"Enhanced training function with comprehensive logging.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    logger.info(f\"üöÄ Starting training for {num_epochs} epochs\")\n",
    "    logger.info(f\"üìä Batch size: {CONFIG['batch_size']}, Total batches: {len(dataloader)}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # Progress bar for epoch\n",
    "        progress_bar = tqdm(\n",
    "            dataloader, \n",
    "            desc=f\"Epoch {epoch+1}/{num_epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(progress_bar):\n",
    "            # Move data to device\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            batch_loss = losses.item()\n",
    "            epoch_loss += batch_loss\n",
    "            training_log['batch_losses'].append(batch_loss)\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_avg = epoch_loss / (batch_idx + 1)\n",
    "            progress_bar.set_postfix({\n",
    "                'batch_loss': f'{batch_loss:.4f}',\n",
    "                'avg_loss': f'{current_avg:.4f}',\n",
    "                'lr': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "            \n",
    "            # Log every 100 batches\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                logger.info(\n",
    "                    f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(dataloader)}: \"\n",
    "                    f\"Loss = {batch_loss:.4f}, Avg = {current_avg:.4f}\"\n",
    "                )\n",
    "        \n",
    "        # Epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        \n",
    "        training_log['epoch_losses'].append(avg_epoch_loss)\n",
    "        training_log['training_times'].append(epoch_time)\n",
    "        training_log['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        logger.info(\n",
    "            f\"‚úÖ Epoch {epoch+1}/{num_epochs} completed in {epoch_time:.2f}s: \"\n",
    "            f\"Avg Loss = {avg_epoch_loss:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Save checkpoint every epoch\n",
    "        checkpoint_path = f\"outputs/models/ssd300_epoch_{epoch+1}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_epoch_loss,\n",
    "            'config': CONFIG\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        logger.info(f\"üíæ Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    total_training_time = time.time() - training_log['start_time']\n",
    "    training_log['total_time'] = total_training_time\n",
    "    \n",
    "    logger.info(f\"üèÅ Training completed in {total_training_time:.2f}s\")\n",
    "    return training_log\n",
    "\n",
    "# Start training\n",
    "print(\"üöÄ Starting model training...\")\n",
    "training_results = train_model(\n",
    "    model, dataloader, optimizer, CONFIG['epochs'], DEVICE\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = \"outputs/models/ssd300_final.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "logger.info(f\"üíæ Final model saved: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training visualizations\n",
    "def create_training_visualizations(training_log):\n",
    "    \"\"\"Create detailed training visualizations.\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. Epoch Loss Curve\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    epochs = range(1, len(training_log['epoch_losses']) + 1)\n",
    "    plt.plot(epochs, training_log['epoch_losses'], 'b-o', linewidth=2, markersize=8)\n",
    "    plt.title('Training Loss per Epoch', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add loss values as annotations\n",
    "    for i, loss in enumerate(training_log['epoch_losses']):\n",
    "        plt.annotate(f'{loss:.3f}', (i+1, loss), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=10)\n",
    "    \n",
    "    # 2. Batch Loss Trend (smoothed)\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    batch_losses = training_log['batch_losses']\n",
    "    # Moving average for smoothing\n",
    "    window = max(1, len(batch_losses) // 100)\n",
    "    smoothed_losses = np.convolve(batch_losses, np.ones(window)/window, mode='valid')\n",
    "    \n",
    "    plt.plot(smoothed_losses, 'r-', alpha=0.7, linewidth=1)\n",
    "    plt.title(f'Batch Losses (Smoothed, window={window})', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Training Time per Epoch\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    plt.bar(epochs, training_log['training_times'], color='green', alpha=0.7)\n",
    "    plt.title('Training Time per Epoch', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add time values as annotations\n",
    "    for i, time_val in enumerate(training_log['training_times']):\n",
    "        plt.text(i+1, time_val + max(training_log['training_times'])*0.01, \n",
    "                f'{time_val:.1f}s', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # 4. Loss Improvement\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    if len(training_log['epoch_losses']) > 1:\n",
    "        improvements = []\n",
    "        for i in range(1, len(training_log['epoch_losses'])):\n",
    "            improvement = training_log['epoch_losses'][i-1] - training_log['epoch_losses'][i]\n",
    "            improvements.append(improvement)\n",
    "        \n",
    "        plt.bar(range(2, len(training_log['epoch_losses']) + 1), improvements, \n",
    "               color='orange', alpha=0.7)\n",
    "        plt.title('Loss Improvement per Epoch', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss Reduction')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 5. Learning Rate Schedule\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    plt.plot(epochs, training_log['learning_rates'], 'purple', marker='s', linewidth=2)\n",
    "    plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Training Summary Statistics\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Calculate statistics\n",
    "    initial_loss = training_log['epoch_losses'][0]\n",
    "    final_loss = training_log['epoch_losses'][-1]\n",
    "    loss_reduction = ((initial_loss - final_loss) / initial_loss) * 100\n",
    "    avg_epoch_time = np.mean(training_log['training_times'])\n",
    "    total_time = training_log['total_time']\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    Training Summary\n",
    "    ================\n",
    "    \n",
    "    üìä Loss Statistics:\n",
    "    ‚Ä¢ Initial Loss: {initial_loss:.4f}\n",
    "    ‚Ä¢ Final Loss: {final_loss:.4f}\n",
    "    ‚Ä¢ Improvement: {loss_reduction:.1f}%\n",
    "    \n",
    "    ‚è±Ô∏è Time Statistics:\n",
    "    ‚Ä¢ Total Time: {total_time:.0f}s ({total_time/60:.1f}m)\n",
    "    ‚Ä¢ Avg per Epoch: {avg_epoch_time:.1f}s\n",
    "    \n",
    "    üîß Configuration:\n",
    "    ‚Ä¢ Epochs: {CONFIG['epochs']}\n",
    "    ‚Ä¢ Batch Size: {CONFIG['batch_size']}\n",
    "    ‚Ä¢ Learning Rate: {CONFIG['learning_rate']}\n",
    "    ‚Ä¢ Device: {DEVICE}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, fontsize=11,\n",
    "            verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('SSD300 Training Analysis Dashboard', fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save visualization\n",
    "    viz_path = 'outputs/visualizations/training_analysis.png'\n",
    "    plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"üìä Training visualization saved: {viz_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "create_training_visualizations(training_results)\n",
    "\n",
    "# Save training log\n",
    "log_path = 'outputs/logs/training_log.json'\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(training_results, f, indent=2)\n",
    "logger.info(f\"üìù Training log saved: {log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced evaluation function\n",
    "def evaluate_model(model, dataset, device, save_predictions=True):\n",
    "    \"\"\"Comprehensive model evaluation with detailed metrics.\"\"\"\n",
    "    logger.info(\"üîç Starting comprehensive model evaluation...\")\n",
    "    \n",
    "    model.eval()\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=CONFIG['batch_size'], \n",
    "                                shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # Load ground truth COCO\n",
    "    coco_gt = COCO(DATA_CONFIG['coco_json_path'])\n",
    "    if 'info' not in coco_gt.dataset:\n",
    "        coco_gt.dataset['info'] = {\"description\": \"VOC to COCO converted dataset\"}\n",
    "    \n",
    "    all_predictions = []\n",
    "    inference_times = []\n",
    "    \n",
    "    logger.info(f\"üìä Running inference on {len(dataset)} images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets) in enumerate(tqdm(eval_dataloader, desc=\"Evaluating\")):\n",
    "            batch_start = time.time()\n",
    "            \n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            \n",
    "            batch_time = time.time() - batch_start\n",
    "            inference_times.append(batch_time / len(images))  # Per image time\n",
    "            \n",
    "            for output, target in zip(outputs, targets):\n",
    "                img_id = target['image_id'].item()\n",
    "                \n",
    "                # Apply confidence filtering\n",
    "                conf_mask = output['scores'] > CONFIG['confidence_threshold']\n",
    "                if conf_mask.sum() == 0:\n",
    "                    continue\n",
    "                \n",
    "                boxes = output['boxes'][conf_mask]\n",
    "                scores = output['scores'][conf_mask]\n",
    "                labels = output['labels'][conf_mask]\n",
    "                \n",
    "                # Apply NMS\n",
    "                keep = nms(boxes, scores, CONFIG['nms_threshold'])\n",
    "                \n",
    "                for i in keep:\n",
    "                    box = boxes[i].cpu().tolist()\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    all_predictions.append({\n",
    "                        \"image_id\": img_id,\n",
    "                        \"category_id\": int(labels[i]) + 1,\n",
    "                        \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
    "                        \"score\": float(scores[i])\n",
    "                    })\n",
    "    \n",
    "    # Calculate inference statistics\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    fps = 1.0 / avg_inference_time\n",
    "    \n",
    "    logger.info(f\"‚ö° Inference speed: {fps:.2f} FPS ({avg_inference_time*1000:.1f} ms/image)\")\n",
    "    logger.info(f\"üìä Generated {len(all_predictions)} predictions\")\n",
    "    \n",
    "    # Save predictions\n",
    "    if save_predictions:\n",
    "        results_path = \"outputs/predictions/ssd300_predictions.json\"\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(all_predictions, f)\n",
    "        logger.info(f\"üíæ Predictions saved: {results_path}\")\n",
    "    \n",
    "    # Run COCO evaluation\n",
    "    logger.info(\"üìà Computing COCO evaluation metrics...\")\n",
    "    \n",
    "    if len(all_predictions) > 0:\n",
    "        coco_dt = coco_gt.loadRes(all_predictions)\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "        \n",
    "        # Filter to images with predictions\n",
    "        img_ids_with_preds = sorted({pred['image_id'] for pred in all_predictions})\n",
    "        coco_eval.params.imgIds = img_ids_with_preds\n",
    "        \n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "        \n",
    "        # Extract metrics\n",
    "        metrics_keys = [\n",
    "            \"AP_0.50:0.95\", \"AP_0.50\", \"AP_0.75\",\n",
    "            \"AP_small\", \"AP_medium\", \"AP_large\",\n",
    "            \"AR_1\", \"AR_10\", \"AR_100\",\n",
    "            \"AR_small\", \"AR_medium\", \"AR_large\"\n",
    "        ]\n",
    "        \n",
    "        evaluation_results = dict(zip(metrics_keys, coco_eval.stats.tolist()))\n",
    "        evaluation_results['inference_fps'] = fps\n",
    "        evaluation_results['avg_inference_time_ms'] = avg_inference_time * 1000\n",
    "        evaluation_results['total_predictions'] = len(all_predictions)\n",
    "        \n",
    "        # Per-class AP\n",
    "        precision = coco_eval.eval['precision']\n",
    "        cat_ids = coco_eval.params.catIds\n",
    "        cat_names = {cat['id']: cat['name'] for cat in coco_gt.loadCats(cat_ids)}\n",
    "        \n",
    "        per_class_ap = {}\n",
    "        for i, cat_id in enumerate(cat_ids):\n",
    "            cat_precision = precision[:, :, i, 0, 2]\n",
    "            ap = np.mean(cat_precision[cat_precision > -1])\n",
    "            per_class_ap[cat_names[cat_id]] = float(ap)\n",
    "        \n",
    "        evaluation_results['per_class_AP'] = per_class_ap\n",
    "        \n",
    "        return evaluation_results, coco_eval\n",
    "    else:\n",
    "        logger.warning(\"‚ö†Ô∏è  No predictions generated - check confidence threshold\")\n",
    "        return None, None\n",
    "\n",
    "# Run evaluation\n",
    "eval_results, coco_evaluator = evaluate_model(model, dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparison Image Testing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comparison_images(model, comparison_images, images_dir, device):\n",
    "    \"\"\"Test model on comparison images and create visualizations.\"\"\"\n",
    "    logger.info(f\"üéØ Testing model on {len(comparison_images)} comparison images...\")\n",
    "    \n",
    "    model.eval()\n",
    "    comparison_results = []\n",
    "    \n",
    "    # Preprocessing transform (without normalization for visualization)\n",
    "    preprocess = T.Compose([\n",
    "        T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Model input transform (with normalization)\n",
    "    model_transform = T.Compose([\n",
    "        T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.48235, 0.45882, 0.40784], \n",
    "                   std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 5, figsize=(25, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, img_info in enumerate(comparison_images[:20]):  # Process first 20 images\n",
    "            img_path = os.path.join(images_dir, img_info['filename'])\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                logger.warning(f\"‚ö†Ô∏è  Image not found: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Load and process image\n",
    "            original_img = Image.open(img_path).convert('RGB')\n",
    "            img_for_viz = preprocess(original_img)\n",
    "            img_for_model = model_transform(original_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Run inference\n",
    "            start_time = time.time()\n",
    "            prediction = model(img_for_model)[0]\n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            # Filter predictions\n",
    "            conf_mask = prediction['scores'] > CONFIG['confidence_threshold']\n",
    "            \n",
    "            if conf_mask.sum() > 0:\n",
    "                boxes = prediction['boxes'][conf_mask]\n",
    "                scores = prediction['scores'][conf_mask]\n",
    "                labels = prediction['labels'][conf_mask]\n",
    "                \n",
    "                # Apply NMS\n",
    "                keep = nms(boxes, scores, CONFIG['nms_threshold'])\n",
    "                boxes = boxes[keep].cpu()\n",
    "                scores = scores[keep].cpu()\n",
    "                labels = labels[keep].cpu()\n",
    "            else:\n",
    "                boxes = torch.empty(0, 4)\n",
    "                scores = torch.empty(0)\n",
    "                labels = torch.empty(0)\n",
    "            \n",
    "            # Store results\n",
    "            comparison_results.append({\n",
    "                'image_info': img_info,\n",
    "                'inference_time_ms': inference_time * 1000,\n",
    "                'detections': len(boxes),\n",
    "                'boxes': boxes.tolist(),\n",
    "                'scores': scores.tolist(),\n",
    "                'labels': labels.tolist()\n",
    "            })\n",
    "            \n",
    "            # Visualize\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Convert tensor to numpy for visualization\n",
    "            img_np = img_for_viz.permute(1, 2, 0).numpy()\n",
    "            ax.imshow(img_np)\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            for box, score, label in zip(boxes, scores, labels):\n",
    "                x1, y1, x2, y2 = box\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "                \n",
    "                # Create rectangle\n",
    "                rect = patches.Rectangle((x1, y1), width, height, \n",
    "                                       linewidth=2, edgecolor='red', \n",
    "                                       facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # Add label\n",
    "                class_name = VOC_CLASSES[int(label)]\n",
    "                ax.text(x1, y1-5, f'{class_name}: {score:.2f}', \n",
    "                       color='red', fontsize=8, fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            # Set title with info\n",
    "            title = f\"{img_info['image_id']}\\n{len(boxes)} det, {inference_time*1000:.1f}ms\"\n",
    "            ax.set_title(title, fontsize=10)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(comparison_images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('SSD300 Predictions on Comparison Images', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Save visualization\n",
    "    comparison_viz_path = 'outputs/visualizations/comparison_predictions.png'\n",
    "    plt.savefig(comparison_viz_path, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"üé® Comparison visualization saved: {comparison_viz_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "# Test on comparison images if available\n",
    "if comparison_images:\n",
    "    comparison_results = test_comparison_images(\n",
    "        model, comparison_images, DATA_CONFIG['images_dir'], DEVICE\n",
    "    )\n",
    "    \n",
    "    # Save comparison results\n",
    "    comparison_path = 'outputs/predictions/ssd300_comparison_results.json'\n",
    "    with open(comparison_path, 'w') as f:\n",
    "        json.dump(comparison_results, f, indent=2)\n",
    "    logger.info(f\"üíæ Comparison results saved: {comparison_path}\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping comparison images (not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Analysis and Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance report\n",
    "def create_final_report(training_results, eval_results, model_info, comparison_results=None):\n",
    "    \"\"\"Generate comprehensive final report.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'session_info': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'device': str(DEVICE),\n",
    "            'pytorch_version': torch.__version__\n",
    "        },\n",
    "        'configuration': CONFIG,\n",
    "        'dataset_stats': dataset_stats,\n",
    "        'model_info': model_info,\n",
    "        'training_results': {\n",
    "            'final_loss': training_results['epoch_losses'][-1],\n",
    "            'loss_reduction_percent': ((training_results['epoch_losses'][0] - training_results['epoch_losses'][-1]) / training_results['epoch_losses'][0]) * 100,\n",
    "            'total_training_time_minutes': training_results['total_time'] / 60,\n",
    "            'avg_epoch_time_minutes': np.mean(training_results['training_times']) / 60\n",
    "        },\n",
    "        'evaluation_results': eval_results if eval_results else {},\n",
    "        'files_generated': {\n",
    "            'final_model': 'outputs/models/ssd300_final.pth',\n",
    "            'predictions': 'outputs/predictions/ssd300_predictions.json',\n",
    "            'training_log': 'outputs/logs/training_log.json',\n",
    "            'visualizations': [\n",
    "                'outputs/visualizations/training_analysis.png',\n",
    "                'outputs/visualizations/comparison_predictions.png'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if comparison_results:\n",
    "        # Analyze comparison results\n",
    "        total_detections = sum(r['detections'] for r in comparison_results)\n",
    "        avg_inference_time = np.mean([r['inference_time_ms'] for r in comparison_results])\n",
    "        \n",
    "        report['comparison_analysis'] = {\n",
    "            'images_tested': len(comparison_results),\n",
    "            'total_detections': total_detections,\n",
    "            'avg_detections_per_image': total_detections / len(comparison_results),\n",
    "            'avg_inference_time_ms': avg_inference_time\n",
    "        }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate final report\n",
    "final_report = create_final_report(\n",
    "    training_results, \n",
    "    eval_results, \n",
    "    model_info, \n",
    "    comparison_results if 'comparison_results' in locals() else None\n",
    ")\n",
    "\n",
    "# Save final report\n",
    "report_path = 'outputs/ssd300_final_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(final_report, f, indent=2)\n",
    "\n",
    "logger.info(f\"üìä Final report saved: {report_path}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ SSD300 TRAINING & EVALUATION COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if eval_results:\n",
    "    print(f\"\\nüìà KEY RESULTS:\")\n",
    "    print(f\"  ‚Ä¢ mAP @ IoU=0.50:0.95: {eval_results['AP_0.50:0.95']:.3f}\")\n",
    "    print(f\"  ‚Ä¢ mAP @ IoU=0.50:     {eval_results['AP_0.50']:.3f}\")\n",
    "    print(f\"  ‚Ä¢ Inference Speed:    {eval_results['inference_fps']:.1f} FPS\")\n",
    "    print(f\"  ‚Ä¢ Training Loss:      {training_results['epoch_losses'][0]:.3f} ‚Üí {training_results['epoch_losses'][-1]:.3f}\")\n",
    "    print(f\"  ‚Ä¢ Training Time:      {training_results['total_time']/60:.1f} minutes\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"  ‚Ä¢ Model:        outputs/models/ssd300_final.pth\")\n",
    "print(f\"  ‚Ä¢ Predictions:  outputs/predictions/ssd300_predictions.json\")\n",
    "print(f\"  ‚Ä¢ Report:       {report_path}\")\n",
    "print(f\"  ‚Ä¢ Logs:         {log_file}\")\n",
    "print(f\"  ‚Ä¢ Visualizations: outputs/visualizations/\")\n",
    "\n",
    "print(f\"\\nüèÜ Ready for model comparison with Faster R-CNN and YOLOv5!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "logger.info(\"‚úÖ SSD300 pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}